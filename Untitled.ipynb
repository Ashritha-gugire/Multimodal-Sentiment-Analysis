{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47591354-9c73-414d-ad2a-a8ca3add0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    CLIPProcessor, CLIPModel, pipeline\n",
    ")\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import io\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21df4f9-83ce-4d91-a325-821452edff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.setup_models()\n",
    "        \n",
    "    @st.cache_resource\n",
    "    def setup_models(_self):\n",
    "        \"\"\"Initialize pre-trained models\"\"\"\n",
    "        try:\n",
    "            # Text sentiment model (BERT-based)\n",
    "            _self.text_tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "            _self.text_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "            \n",
    "            # CLIP model for image-text understanding\n",
    "            _self.clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "            _self.clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "            \n",
    "            # Emotion detection pipeline\n",
    "            _self.emotion_pipeline = pipeline(\"text-classification\", \n",
    "                                            model=\"j-hartmann/emotion-english-distilroberta-base\", \n",
    "                                            return_all_scores=True)\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error loading models: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and preprocess text\"\"\"\n",
    "        # Remove URLs, mentions, hashtags\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        return text\n",
    "    \n",
    "    def analyze_text_sentiment(self, text):\n",
    "        \"\"\"Analyze sentiment of text using BERT-based model\"\"\"\n",
    "        try:\n",
    "            # Preprocess text\n",
    "            clean_text = self.preprocess_text(text)\n",
    "            \n",
    "            # Tokenize and predict\n",
    "            inputs = self.text_tokenizer(clean_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.text_model(**inputs)\n",
    "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            \n",
    "            # Map labels (RoBERTa sentiment model uses LABEL_0=negative, LABEL_1=neutral, LABEL_2=positive)\n",
    "            labels = ['negative', 'neutral', 'positive']\n",
    "            scores = predictions[0].numpy()\n",
    "            \n",
    "            result = {\n",
    "                'text': text,\n",
    "                'sentiment': labels[np.argmax(scores)],\n",
    "                'confidence': float(np.max(scores)),\n",
    "                'scores': {\n",
    "                    'negative': float(scores[0]),\n",
    "                    'neutral': float(scores[1]),\n",
    "                    'positive': float(scores[2])\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Add emotion analysis\n",
    "            emotions = self.emotion_pipeline(clean_text)[0]\n",
    "            result['emotions'] = {emotion['label']: emotion['score'] for emotion in emotions}\n",
    "            \n",
    "            # TextBlob for additional insights\n",
    "            blob = TextBlob(clean_text)\n",
    "            result['polarity'] = blob.sentiment.polarity\n",
    "            result['subjectivity'] = blob.sentiment.subjectivity\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error in text analysis: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_image_sentiment(self, image):\n",
    "        \"\"\"Analyze sentiment of image using CLIP and emotion detection\"\"\"\n",
    "        try:\n",
    "            # Convert PIL image to RGB if needed\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            # Emotion prompts for CLIP\n",
    "            emotion_prompts = [\n",
    "                \"a happy person\", \"a sad person\", \"an angry person\",\n",
    "                \"a surprised person\", \"a disgusted person\", \"a fearful person\",\n",
    "                \"a neutral expression\", \"positive emotions\", \"negative emotions\"\n",
    "            ]\n",
    "            \n",
    "            # Process image and text prompts\n",
    "            inputs = self.clip_processor(text=emotion_prompts, images=image, return_tensors=\"pt\", padding=True)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.clip_model(**inputs)\n",
    "                logits_per_image = outputs.logits_per_image\n",
    "                probs = logits_per_image.softmax(dim=-1)\n",
    "            \n",
    "            # Map probabilities to emotions\n",
    "            emotion_scores = probs[0].numpy()\n",
    "            emotions = ['happy', 'sad', 'angry', 'surprised', 'disgusted', 'fearful', 'neutral', 'positive', 'negative']\n",
    "            \n",
    "            # Calculate overall sentiment\n",
    "            positive_score = emotion_scores[0] + emotion_scores[3] + emotion_scores[7]  # happy + surprised + positive\n",
    "            negative_score = emotion_scores[1] + emotion_scores[2] + emotion_scores[4] + emotion_scores[5] + emotion_scores[8]  # sad + angry + disgusted + fearful + negative\n",
    "            neutral_score = emotion_scores[6]  # neutral\n",
    "            \n",
    "            # Normalize scores\n",
    "            total = positive_score + negative_score + neutral_score\n",
    "            if total > 0:\n",
    "                positive_score /= total\n",
    "                negative_score /= total\n",
    "                neutral_score /= total\n",
    "            \n",
    "            # Determine primary sentiment\n",
    "            sentiment_scores = [negative_score, neutral_score, positive_score]\n",
    "            sentiment_labels = ['negative', 'neutral', 'positive']\n",
    "            primary_sentiment = sentiment_labels[np.argmax(sentiment_scores)]\n",
    "            \n",
    "            # Color analysis\n",
    "            img_array = np.array(image)\n",
    "            avg_color = np.mean(img_array, axis=(0, 1))\n",
    "            brightness = np.mean(avg_color)\n",
    "            \n",
    "            result = {\n",
    "                'sentiment': primary_sentiment,\n",
    "                'confidence': float(np.max(sentiment_scores)),\n",
    "                'scores': {\n",
    "                    'negative': float(negative_score),\n",
    "                    'neutral': float(neutral_score),\n",
    "                    'positive': float(positive_score)\n",
    "                },\n",
    "                'detailed_emotions': {emotions[i]: float(emotion_scores[i]) for i in range(len(emotions))},\n",
    "                'color_analysis': {\n",
    "                    'average_rgb': avg_color.tolist(),\n",
    "                    'brightness': float(brightness),\n",
    "                    'warmth': 'warm' if avg_color[0] > avg_color[2] else 'cool'\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error in image analysis: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def combine_analyses(self, text_result, image_result, text_weight=0.6, image_weight=0.4):\n",
    "        \"\"\"Combine text and image sentiment analyses\"\"\"\n",
    "        try:\n",
    "            # Weighted combination of scores\n",
    "            combined_scores = {\n",
    "                'negative': text_result['scores']['negative'] * text_weight + image_result['scores']['negative'] * image_weight,\n",
    "                'neutral': text_result['scores']['neutral'] * text_weight + image_result['scores']['neutral'] * image_weight,\n",
    "                'positive': text_result['scores']['positive'] * text_weight + image_result['scores']['positive'] * image_weight\n",
    "            }\n",
    "            \n",
    "            # Determine overall sentiment\n",
    "            sentiment_labels = ['negative', 'neutral', 'positive']\n",
    "            primary_sentiment = max(combined_scores, key=combined_scores.get)\n",
    "            confidence = combined_scores[primary_sentiment]\n",
    "            \n",
    "            # Agreement analysis\n",
    "            text_sentiment = text_result['sentiment']\n",
    "            image_sentiment = image_result['sentiment']\n",
    "            agreement = text_sentiment == image_sentiment\n",
    "            \n",
    "            result = {\n",
    "                'sentiment': primary_sentiment,\n",
    "                'confidence': float(confidence),\n",
    "                'scores': combined_scores,\n",
    "                'agreement': agreement,\n",
    "                'text_weight': text_weight,\n",
    "                'image_weight': image_weight,\n",
    "                'individual_results': {\n",
    "                    'text': text_result,\n",
    "                    'image': image_result\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error in combining analyses: {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d549ba-f278-493a-bb6b-7204337a8c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_visualization(results, analysis_type):\n",
    "    \"\"\"Create visualizations for sentiment analysis results\"\"\"\n",
    "    \n",
    "    if analysis_type == 'text' and 'emotions' in results:\n",
    "        # Emotion distribution pie chart\n",
    "        emotions = results['emotions']\n",
    "        fig_emotions = px.pie(\n",
    "            values=list(emotions.values()),\n",
    "            names=list(emotions.keys()),\n",
    "            title=\"Emotion Distribution\"\n",
    "        )\n",
    "        st.plotly_chart(fig_emotions)\n",
    "    \n",
    "    # Sentiment scores bar chart\n",
    "    scores = results['scores']\n",
    "    fig_sentiment = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=list(scores.keys()),\n",
    "            y=list(scores.values()),\n",
    "            marker_color=['red', 'gray', 'green']\n",
    "        )\n",
    "    ])\n",
    "    fig_sentiment.update_layout(\n",
    "        title=f\"Sentiment Scores - {analysis_type.title()} Analysis\",\n",
    "        xaxis_title=\"Sentiment\",\n",
    "        yaxis_title=\"Score\"\n",
    "    )\n",
    "    st.plotly_chart(fig_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26dfc5b6-e231-48cf-882e-3128509c83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    st.set_page_config(page_title=\"Multimodal Sentiment Analysis\", page_icon=\"üé≠\", layout=\"wide\")\n",
    "    \n",
    "    st.title(\"Multimodal Sentiment Analysis\")\n",
    "    st.markdown(\"Advanced sentiment analysis using state-of-the-art AI models for text and images\")\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    if 'analyzer' not in st.session_state:\n",
    "        with st.spinner(\"Loading AI models... This may take a moment.\"):\n",
    "            st.session_state.analyzer = MultimodalSentimentAnalyzer()\n",
    "    \n",
    "    analyzer = st.session_state.analyzer\n",
    "    \n",
    "    # Sidebar configuration\n",
    "    st.sidebar.header(\"Configuration\")\n",
    "    analysis_mode = st.sidebar.selectbox(\n",
    "        \"Analysis Mode\",\n",
    "        [\"Text Only\", \"Image Only\", \"Multimodal (Text + Image)\"]\n",
    "    )\n",
    "    \n",
    "    if analysis_mode == \"Multimodal (Text + Image)\":\n",
    "        text_weight = st.sidebar.slider(\"Text Weight\", 0.0, 1.0, 0.6, 0.1)\n",
    "        image_weight = 1.0 - text_weight\n",
    "        st.sidebar.write(f\"Image Weight: {image_weight:.1f}\")\n",
    "    \n",
    "    # Main interface\n",
    "    col1, col2 = st.columns([2, 1])\n",
    "    \n",
    "    with col1:\n",
    "        # Text input\n",
    "        if analysis_mode in [\"Text Only\", \"Multimodal (Text + Image)\"]:\n",
    "            st.subheader(\" Text Input\")\n",
    "            text_input = st.text_area(\n",
    "                \"Enter text to analyze:\",\n",
    "                placeholder=\"Type your message here... Try: 'I absolutely love this amazing product!' or 'This service was terrible and disappointing.'\",\n",
    "                height=100\n",
    "            )\n",
    "        \n",
    "        # Image input\n",
    "        if analysis_mode in [\"Image Only\", \"Multimodal (Text + Image)\"]:\n",
    "            st.subheader(\"Image Input\")\n",
    "            uploaded_image = st.file_uploader(\n",
    "                \"Upload an image:\",\n",
    "                type=['png', 'jpg', 'jpeg'],\n",
    "                help=\"Upload an image containing faces or emotional content\"\n",
    "            )\n",
    "            \n",
    "            if uploaded_image:\n",
    "                image = Image.open(uploaded_image)\n",
    "                st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "    \n",
    "    with col2:\n",
    "        st.subheader(\" Quick Test Examples\")\n",
    "        \n",
    "        if st.button(\"üòä Positive Text Example\"):\n",
    "            st.session_state.sample_text = \"I absolutely love this fantastic product! The quality is amazing and the customer service exceeded my expectations. Highly recommended!\"\n",
    "        \n",
    "        if st.button(\"üò¢ Negative Text Example\"):\n",
    "            st.session_state.sample_text = \"This product is terrible and completely disappointing. The quality is poor and the customer service was unhelpful and rude.\"\n",
    "        \n",
    "        if st.button(\"üòê Neutral Text Example\"):\n",
    "            st.session_state.sample_text = \"The product arrived on time. It functions as described in the documentation. The packaging was adequate.\"\n",
    "        \n",
    "        # Use sample text if set\n",
    "        if 'sample_text' in st.session_state:\n",
    "            text_input = st.session_state.sample_text\n",
    "            del st.session_state.sample_text\n",
    "    \n",
    "    # Analysis button\n",
    "    if st.button(\" Analyze Sentiment\", type=\"primary\"):\n",
    "        \n",
    "        # Validate inputs\n",
    "        has_text = analysis_mode in [\"Text Only\", \"Multimodal (Text + Image)\"] and text_input.strip()\n",
    "        has_image = analysis_mode in [\"Image Only\", \"Multimodal (Text + Image)\"] and uploaded_image is not None\n",
    "        \n",
    "        if not has_text and analysis_mode in [\"Text Only\", \"Multimodal (Text + Image)\"]:\n",
    "            st.error(\"Please enter some text to analyze.\")\n",
    "            return\n",
    "        \n",
    "        if not has_image and analysis_mode in [\"Image Only\", \"Multimodal (Text + Image)\"]:\n",
    "            st.error(\"Please upload an image to analyze.\")\n",
    "            return\n",
    "        \n",
    "        # Perform analysis\n",
    "        with st.spinner(\"Analyzing sentiment...\"):\n",
    "            results = {}\n",
    "            \n",
    "            # Text analysis\n",
    "            if has_text:\n",
    "                with st.status(\"Analyzing text sentiment...\"):\n",
    "                    text_result = analyzer.analyze_text_sentiment(text_input)\n",
    "                    if text_result:\n",
    "                        results['text'] = text_result\n",
    "            \n",
    "            # Image analysis\n",
    "            if has_image:\n",
    "                with st.status(\"Analyzing image sentiment...\"):\n",
    "                    image_result = analyzer.analyze_image_sentiment(image)\n",
    "                    if image_result:\n",
    "                        results['image'] = image_result\n",
    "            \n",
    "            # Combined analysis\n",
    "            if analysis_mode == \"Multimodal (Text + Image)\" and 'text' in results and 'image' in results:\n",
    "                with st.status(\"Combining analyses...\"):\n",
    "                    combined_result = analyzer.combine_analyses(\n",
    "                        results['text'], \n",
    "                        results['image'], \n",
    "                        text_weight, \n",
    "                        image_weight\n",
    "                    )\n",
    "                    if combined_result:\n",
    "                        results['combined'] = combined_result\n",
    "        \n",
    "        # Display results\n",
    "        if results:\n",
    "            st.success(\"Analysis completed!\")\n",
    "            \n",
    "            # Results tabs\n",
    "            if analysis_mode == \"Text Only\":\n",
    "                display_text_results(results['text'])\n",
    "            elif analysis_mode == \"Image Only\":\n",
    "                display_image_results(results['image'])\n",
    "            else:  # Multimodal\n",
    "                tab1, tab2, tab3 = st.tabs([\" Combined Analysis\", \" Text Analysis\", \" Image Analysis\"])\n",
    "                \n",
    "                with tab1:\n",
    "                    display_combined_results(results['combined'])\n",
    "                \n",
    "                with tab2:\n",
    "                    display_text_results(results['text'])\n",
    "                \n",
    "                with tab3:\n",
    "                    display_image_results(results['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cc217e1-a340-42cf-a094-647695651aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_text_results(result):\n",
    "    \"\"\"Display text analysis results\"\"\"\n",
    "    st.subheader(\"Text Sentiment Analysis\")\n",
    "    \n",
    "    # Main sentiment\n",
    "    sentiment = result['sentiment']\n",
    "    confidence = result['confidence']\n",
    "    \n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    with col1:\n",
    "        st.metric(\"Sentiment\", sentiment.title(), f\"{confidence:.1%} confidence\")\n",
    "    with col2:\n",
    "        st.metric(\"Polarity\", f\"{result['polarity']:.2f}\", \"(-1 to +1)\")\n",
    "    with col3:\n",
    "        st.metric(\"Subjectivity\", f\"{result['subjectivity']:.2f}\", \"(0 to 1)\")\n",
    "    \n",
    "    # Sentiment scores\n",
    "    create_sentiment_visualization(result, 'text')\n",
    "    \n",
    "    # Detailed metrics\n",
    "    with st.expander(\"Detailed Metrics\"):\n",
    "        st.json(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c585a367-8731-40e9-97dd-f1ad82575f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_results(result):\n",
    "    \"\"\"Display image analysis results\"\"\"\n",
    "    st.subheader(\"Image Sentiment Analysis\")\n",
    "    \n",
    "    # Main sentiment\n",
    "    sentiment = result['sentiment']\n",
    "    confidence = result['confidence']\n",
    "    \n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    with col1:\n",
    "        st.metric(\"Sentiment\", sentiment.title(), f\"{confidence:.1%} confidence\")\n",
    "    with col2:\n",
    "        color_analysis = result['color_analysis']\n",
    "        st.metric(\"Brightness\", f\"{color_analysis['brightness']:.0f}\", f\"{color_analysis['warmth']} tones\")\n",
    "    with col3:\n",
    "        dominant_emotion = max(result['detailed_emotions'], key=result['detailed_emotions'].get)\n",
    "        st.metric(\"Dominant Emotion\", dominant_emotion.title())\n",
    "    \n",
    "    # Visualizations\n",
    "    create_sentiment_visualization(result, 'image')\n",
    "    \n",
    "    # Detailed emotions\n",
    "    with st.expander(\"üòä Detailed Emotions\"):\n",
    "        emotions_df = pd.DataFrame([\n",
    "            {\"Emotion\": k.title(), \"Score\": f\"{v:.3f}\"} \n",
    "            for k, v in result['detailed_emotions'].items()\n",
    "        ])\n",
    "        st.dataframe(emotions_df, use_container_width=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "affc2dbf-8099-4f3f-b90d-3dbc8fd1f8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 12:53:57.064 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:57.079 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.014 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\ashri\\anaconda3\\envs\\research_env\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-11 12:53:58.017 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.019 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.020 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.021 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.022 Session state does not function when running a script without `streamlit run`\n",
      "2025-06-11 12:53:58.025 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.026 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.028 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.034 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.035 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.036 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.538 Thread 'Thread-3': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.548 Thread 'Thread-4': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.549 Thread 'Thread-3': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:53:58.553 Thread 'Thread-4': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fc93865fe34c85b4b0fa3bcfca51e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashri\\anaconda3\\envs\\research_env\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ashri\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368e5c1f2d744588825589e751673529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3b335707bb458c818b8e6b770ab4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8125e4f0534ce1a4bdcbc31a776efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2f1d9c724a455687ad3b7fc5734f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b79792fd95847c9a6be2626e2ffeb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashri\\anaconda3\\envs\\research_env\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ashri\\.cache\\huggingface\\hub\\models--openai--clip-vit-base-patch32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ccb5f7dff34b71a4c162cd70c46b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6c04b9c75b481aa1f4058df9ab6058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c2ab5c060147e3bfa3f9c6e188d372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902b19181c56449baa5c0e6fd20ea2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ada610f8094229bf6fc0f7a6b26ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2970d7b547cd40feaa58cb8188eef404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f67f909f234e20b0992d9981533b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77956af020d4f10a16e1d2abcd23c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51383712d0c547268519101408263a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashri\\anaconda3\\envs\\research_env\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ashri\\.cache\\huggingface\\hub\\models--j-hartmann--emotion-english-distilroberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d80dac1a58549e5b60e7d1b24f87da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add610651b5d45e79ce14820ce39e9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692890b01ab043e3949a0906c0048211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/294 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1782a2b2b5554482b2eed475f7fc1b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ad99bf170a49dda1f708b2ca6237f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32cc83e131d043e0b72669162d627a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1091e122c941048f4a568ed6022a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\ashri\\anaconda3\\envs\\research_env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "2025-06-11 12:54:39.248 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.251 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.253 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.255 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.257 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.259 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.261 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.266 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.267 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.271 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.276 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.284 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.287 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.292 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.293 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.294 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.299 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.300 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.301 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.304 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.305 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.306 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.307 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.308 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.309 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.310 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.318 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.322 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.324 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.325 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.326 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.329 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.330 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.330 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.332 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.332 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.333 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.334 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.335 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.336 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.338 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-11 12:54:39.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "def display_combined_results(result):\n",
    "    \"\"\"Display combined analysis results\"\"\"\n",
    "    st.subheader(\"Combined Multimodal Analysis\")\n",
    "    \n",
    "    # Main metrics\n",
    "    sentiment = result['sentiment']\n",
    "    confidence = result['confidence']\n",
    "    agreement = result['agreement']\n",
    "    \n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    with col1:\n",
    "        st.metric(\"Final Sentiment\", sentiment.title(), f\"{confidence:.1%} confidence\")\n",
    "    with col2:\n",
    "        st.metric(\"Modality Agreement\", \" Yes\" if agreement else \" No\")\n",
    "    with col3:\n",
    "        st.metric(\"Combination\", f\"Text: {result['text_weight']:.0%}, Image: {result['image_weight']:.0%}\")\n",
    "    \n",
    "    # Combined scores\n",
    "    create_sentiment_visualization(result, 'combined')\n",
    "    \n",
    "    # Agreement analysis\n",
    "    with st.expander(\"ü§ù Agreement Analysis\"):\n",
    "        text_sent = result['individual_results']['text']['sentiment']\n",
    "        image_sent = result['individual_results']['image']['sentiment']\n",
    "        \n",
    "        if agreement:\n",
    "            st.success(f\"Both text and image analysis agree on **{sentiment}** sentiment\")\n",
    "        else:\n",
    "            st.warning(f\"‚ö†Ô∏è Disagreement: Text shows **{text_sent}** while image shows **{image_sent}**\")\n",
    "        \n",
    "        st.write(\"This disagreement could indicate:\")\n",
    "        st.write(\"- Sarcasm or irony in text\")\n",
    "        st.write(\"- Mismatched emotional content\")\n",
    "        st.write(\"- Contextual nuances requiring human interpretation\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a756981-3581-40df-b9dd-27954d935853",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multimodal_code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the multimodal sentiment analysis file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mashri\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmultimodal Sentiment Analysis\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmultimodal_sentiment_app.py\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 3\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mmultimodal_code\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated multimodal_sentiment_app.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'multimodal_code' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the multimodal sentiment analysis file\n",
    "with open('C:\\\\Users\\\\ashri\\\\Documents\\\\multimodal Sentiment Analysis\\\\multimodal_sentiment_app.py', 'w') as f:\n",
    "    f.write(multimodal_code)\n",
    "\n",
    "print(\"Created multimodal_sentiment_app.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b059852b-dfac-44fd-aabc-b8c62a352eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
